{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MSc: learning a Gaussian with tensorflow"
      ],
      "metadata": {
        "id": "GCW3Kd1LLf12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WijH8Q6aLbPR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import scipy.io\n",
        "import scipy.sparse\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the iris data set."
      ],
      "metadata": {
        "id": "2mv-19QmMLuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()['data']"
      ],
      "metadata": {
        "id": "k5oATPkOL0WZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = ((data - np.mean(data,0))/np.std(data,0)).astype(np.float32)\n",
        "n = x.shape[0] # number of observations\n",
        "p = x.shape[1] # number of features"
      ],
      "metadata": {
        "id": "3jUaY-jkL81Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn a Gaussian model $p(x) = \\mathcal{N}(x|\\mu,\\Sigma)$ using Tensorflow!"
      ],
      "metadata": {
        "id": "kfTETUDnMPbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = tf.Variable(tf.random.normal([p]), trainable=True)\n",
        "L_undiag = tf.Variable(tfp.math.fill_triangular(tf.random.normal([int(p*(p+1)/2)]))) "
      ],
      "metadata": {
        "id": "HmFB0Y6uNDSj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = tf.linalg.set_diag(L_undiag,tf.exp(tf.linalg.diag_part(L_undiag))) # L corresponds to the Cholesky decomposition"
      ],
      "metadata": {
        "id": "tryfxwTEVTG6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sigma = tf.matmul(L,L,transpose_b= True) # L*L^T"
      ],
      "metadata": {
        "id": "Za2O0bFEjqeg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check that $\\Sigma$ is indeed a positive definite matrix, by checking that it's indeed symmetric with nonnegative eigenvalues."
      ],
      "metadata": {
        "id": "C63t-J5Jqd7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Sigma.numpy()) \n",
        "print(np.linalg.eigvals(Sigma.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vODr8YUj-XQ",
        "outputId": "4ff02c51-4e39-485b-f9db-c372cb9ad2a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.3217838  2.7583165 -2.073172   1.3955039]\n",
            " [ 2.7583165 17.793037   6.5375595  0.6485721]\n",
            " [-2.073172   6.5375595  6.230428   0.3784474]\n",
            " [ 1.3955039  0.6485721  0.3784474  5.350596 ]]\n",
            "[2.0950649e+01 1.7065268e-02 6.7815847e+00 4.9465461e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by computing the likelihood of a single data point."
      ],
      "metadata": {
        "id": "JFrzLP-pWkil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gaussian = tfd.MultivariateNormalFullCovariance(loc = mu, covariance_matrix = Sigma) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mtWytObVUEa",
        "outputId": "71f76071-dcbd-406c-f5de-730656aeec94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py:342: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\n",
            "Instructions for updating:\n",
            "`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gaussian.log_prob(x[:1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vytb837W4fZ",
        "outputId": "3af8414f-c66c-405b-8aa6-41392ef7eab8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-217.53217], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll do a custom training loop for our unknown mean. We first define our loss function."
      ],
      "metadata": {
        "id": "cCyn4fDFXNdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood(x):\n",
        "  L = tf.linalg.set_diag(L_undiag,tf.exp(tf.linalg.diag_part(L_undiag)))\n",
        "  Sigma = tf.matmul(L,L,transpose_b= True) \n",
        "  gaussian = tfd.MultivariateNormalFullCovariance(loc = mu, covariance_matrix = Sigma)\n",
        "  return(tf.reduce_mean(gaussian.log_prob(x)))"
      ],
      "metadata": {
        "id": "QewCgsroW6KE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we define the paramaters we want to optimise, and we define a gradient step."
      ],
      "metadata": {
        "id": "FBRZmpmjbcji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = [mu] + [L_undiag]\n",
        "optimizer = tfk.optimizers.Adam(learning_rate = 0.01)"
      ],
      "metadata": {
        "id": "hpqRe6QVbRNo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(data): # data is a batch of data points\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = - log_likelihood(data)\n",
        "  gradients = tape.gradient(loss, params) # here we compute gradients\n",
        "  optimizer.apply_gradients(zip(gradients,params))"
      ],
      "metadata": {
        "id": "wlXpaoYybvDC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x)).shuffle(n).batch(batch_size = 16)"
      ],
      "metadata": {
        "id": "jSFOFbj1cb17"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "  for data_batch in train_dataset:\n",
        "    train_step(data_batch)\n",
        "  if (epoch % 10) == 1:\n",
        "    print(log_likelihood(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Lb1rFPfA7b",
        "outputId": "cf97da85-a264-4df3-f29f-8902b3a1561e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(-12.608184, shape=(), dtype=float32)\n",
            "tf.Tensor(-8.395755, shape=(), dtype=float32)\n",
            "tf.Tensor(-7.686512, shape=(), dtype=float32)\n",
            "tf.Tensor(-7.282068, shape=(), dtype=float32)\n",
            "tf.Tensor(-6.9156876, shape=(), dtype=float32)\n",
            "tf.Tensor(-6.528509, shape=(), dtype=float32)\n",
            "tf.Tensor(-6.107011, shape=(), dtype=float32)\n",
            "tf.Tensor(-5.657769, shape=(), dtype=float32)\n",
            "tf.Tensor(-5.118271, shape=(), dtype=float32)\n",
            "tf.Tensor(-4.3964, shape=(), dtype=float32)\n",
            "tf.Tensor(-4.006534, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.718487, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.4759986, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.3386252, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.305196, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.2854435, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.2791643, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.2717423, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.2697456, shape=(), dtype=float32)\n",
            "tf.Tensor(-3.2697082, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-brcUpGfdaf",
        "outputId": "f13bb6f0-0e92-4ce4-a3f9-5c6745035b1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0.00570357, 0.00027669, 0.01256279, 0.00723899], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  L = tf.linalg.set_diag(L_undiag,tf.exp(tf.linalg.diag_part(L_undiag)))\n",
        "  Sigma = tf.matmul(L,L,transpose_b= True) # L*L^T"
      ],
      "metadata": {
        "id": "JV622e95f3b6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sigma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PeRHqdSk0ej",
        "outputId": "31f85fbb-5719-4e0f-f564-a8ab63109990"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[ 1.0315608 , -0.13662878,  0.9013501 ,  0.8399476 ],\n",
              "       [-0.13662878,  0.9979911 , -0.44282168, -0.3924243 ],\n",
              "       [ 0.9013501 , -0.44282168,  1.0279208 ,  0.9879363 ],\n",
              "       [ 0.8399476 , -0.3924243 ,  0.9879363 ,  1.0253401 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.cov(x, rowvar = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqxYfZnik65c",
        "outputId": "55697832-770c-477b-fbdb-21df623339aa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00671141, -0.11835884,  0.87760447,  0.82343068],\n",
              "       [-0.11835884,  1.0067114 , -0.43131554, -0.36858316],\n",
              "       [ 0.87760447, -0.43131554,  1.0067114 ,  0.96932763],\n",
              "       [ 0.82343068, -0.36858316,  0.96932763,  1.00671144]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ue4-zdl7k-_7"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}